input {
  # Zeek JSON logs
  file {
    path => "/path/to/zeek/logs/current/*.log"
    codec => json
    type => "zeek"
    tags => ["zeek"]
  }

  # Suricata alerts via Redis
  redis {
    host => "redis"
    port => 6379
    data_type => "list"
    key => "suricata"
    codec => json
    type => "suricata"
    tags => ["suricata"]
  }

  # Kafka input for application logs
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => ["ndrv1-logs", "ndrv1-events"]
    codec => json
    type => "application"
    tags => ["application"]
  }
}

filter {
  if [type] == "zeek" {
    # Process Zeek logs
    if [id] {
      mutate {
        rename => { "id.orig_h" => "source_ip" }
        rename => { "id.orig_p" => "source_port" }
        rename => { "id.resp_h" => "destination_ip" }
        rename => { "id.resp_p" => "destination_port" }
      }
    }
    
    # Add geo information for IPs
    if [source_ip] {
      geoip {
        source => "source_ip"
        target => "source_geo"
      }
    }
    
    if [destination_ip] {
      geoip {
        source => "destination_ip"
        target => "destination_geo"
      }
    }
    
    # Extract log type from filename
    grok {
      match => { "path" => "%{GREEDYDATA}/%{GREEDYDATA:log_type}\.log" }
    }
    
    # Add timestamp in ISO format
    date {
      match => [ "ts", "UNIX" ]
      target => "@timestamp"
    }
  }
  
  if [type] == "suricata" {
    # Process Suricata logs
    if [src_ip] {
      mutate {
        rename => { "src_ip" => "source_ip" }
        rename => { "src_port" => "source_port" }
        rename => { "dest_ip" => "destination_ip" }
        rename => { "dest_port" => "destination_port" }
      }
    }
    
    # Add geo information for IPs
    if [source_ip] {
      geoip {
        source => "source_ip"
        target => "source_geo"
      }
    }
    
    if [destination_ip] {
      geoip {
        source => "destination_ip"
        target => "destination_geo"
      }
    }
    
    # Extract alert severity
    if [alert] and [alert][severity] {
      mutate {
        add_field => { "severity" => "%{[alert][severity]}" }
      }
    }
    
    # Add timestamp in ISO format
    date {
      match => [ "timestamp", "ISO8601" ]
      target => "@timestamp"
    }
  }
  
  # Normalize fields across different log sources
  mutate {
    add_field => { "ndr_source" => "%{type}" }
    add_field => { "log_timestamp" => "%{@timestamp}" }
  }
  
  # Enrich events with threat intelligence
  if [source_ip] or [destination_ip] {
    http {
      url => "http://backend:8080/api/v1/threat-intelligence/lookup"
      verb => "POST"
      body => {
        "source_ip" => "%{[source_ip]}"
        "destination_ip" => "%{[destination_ip]}"
      }
      body_format => "json"
      target_body => "threat_intel"
      response_headers => false
    }
  }
}

output {
  # Send all events to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "ndrv1-events-%{+YYYY.MM.dd}"
    document_type => "_doc"
  }
  
  # Send critical alerts to Kafka for real-time processing
  if [severity] == "1" or [severity] == "critical" or [alert] {
    kafka {
      bootstrap_servers => "kafka:9092"
      topic_id => "ndrv1-alerts"
      codec => json
    }
  }
  
  # Cache recent events in Redis for dashboard
  redis {
    host => "redis"
    port => 6379
    data_type => "list"
    key => "recent_events"
    congestion_interval => 1
    congestion_threshold => 10000
  }
}