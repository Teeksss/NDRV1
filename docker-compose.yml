version: '3.8'

services:
  # Frontend ve Backend
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    ports:
      - "80:80"
    depends_on:
      - backend
    networks:
      - ndr-network
    restart: unless-stopped

  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    ports:
      - "8080:8080"
    depends_on:
      - elasticsearch
      - redis
      - kafka
      - suricata
      - zeek
    environment:
      - SPRING_PROFILES_ACTIVE=prod
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - KAFKA_BROKERS=kafka:9092
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - ZEEK_HOST=zeek
      - ZEEK_PORT=9200
      - SURICATA_HOST=suricata
      - SURICATA_PORT=9200
      - ARKIME_URL=http://arkime:8005
    volumes:
      - backend-data:/app/data
    networks:
      - ndr-network
    restart: unless-stopped

  # Trafik Analizi ve Tehdit Tespiti
  zeek:
    image: zeek/zeek:latest
    restart: unless-stopped
    network_mode: "host"
    cap_add:
      - NET_RAW
      - NET_ADMIN
    volumes:
      - ./config/zeek/:/opt/zeek/share/zeek/site/
      - zeek-logs:/opt/zeek/logs/
    command: -i ${CAPTURE_INTERFACE:-eth0}
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "3"

  suricata:
    image: jasonish/suricata:latest
    restart: unless-stopped
    network_mode: "host"
    cap_add:
      - NET_ADMIN
      - SYS_NICE
      - NET_RAW
    volumes:
      - ./config/suricata/suricata.yaml:/etc/suricata/suricata.yaml
      - ./config/suricata/rules:/etc/suricata/rules
      - suricata-logs:/var/log/suricata
    command: -i ${CAPTURE_INTERFACE:-eth0} --set outputs.eve-log.filetype=redis --set outputs.eve-log.redis.server=redis --set outputs.eve-log.redis.port=6379
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "3"

  arkime:
    image: arkime/arkime:latest
    restart: unless-stopped
    network_mode: "host"
    cap_add:
      - NET_ADMIN
      - NET_RAW
    depends_on:
      - elasticsearch
    volumes:
      - ./config/arkime/config.ini:/data/config.ini
      - arkime-data:/data
      - pcap-data:/data/pcap
    environment:
      - ELASTICSEARCH=http://elasticsearch:9200
      - INTERFACE=${CAPTURE_INTERFACE:-eth0}
      - ARKIME_PASSWORD=${ADMIN_PASSWORD:-admin}
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "3"

  # Veri Depolama ve Analizi
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.16.3
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - xpack.security.enabled=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - ndr-network
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "3"

  logstash:
    image: docker.elastic.co/logstash/logstash:7.16.3
    restart: unless-stopped
    depends_on:
      - elasticsearch
      - kafka
    volumes:
      - ./config/logstash/pipeline:/usr/share/logstash/pipeline
      - ./config/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml
    environment:
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    networks:
      - ndr-network
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "3"

  kibana:
    image: docker.elastic.co/kibana/kibana:7.16.3
    restart: unless-stopped
    depends_on:
      - elasticsearch
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    networks:
      - ndr-network
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "3"

  # Mesaj Kuyruk ve Önbellek
  kafka:
    image: confluentinc/cp-kafka:7.0.1
    restart: unless-stopped
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - ndr-network
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "3"

  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-logs:/var/lib/zookeeper/log
    networks:
      - ndr-network
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "3"

  redis:
    image: redis:7.0-alpine
    restart: unless-stopped
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    ports:
      - "6379:6379"
    networks:
      - ndr-network
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "3"

  # İzleme ve Metrikler
  prometheus:
    image: prom/prometheus:v2.36.2
    restart: unless-stopped
    volumes:
      - ./config/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    ports:
      - "9090:9090"
    networks:
      - ndr-network
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "3"

  grafana:
    image: grafana/grafana:9.0.2
    restart: unless-stopped
    depends_on:
      - prometheus
    volumes:
      - ./config/grafana/provisioning:/etc/grafana/provisioning
      - grafana-data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    ports:
      - "3000:3000"
    networks:
      - ndr-network
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "3"

networks:
  ndr-network:
    driver: bridge

volumes:
  backend-data:
  elasticsearch-data:
  kafka-data:
  zookeeper-data:
  zookeeper-logs:
  redis-data:
  prometheus-data:
  grafana-data:
  zeek-logs:
  suricata-logs:
  arkime-data:
  pcap-data: